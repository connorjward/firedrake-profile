  Linear firedrake_0_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_1_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_2_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_3_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_4_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_5_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_6_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_7_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_8_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_9_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_10_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_11_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_12_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_13_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_14_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_15_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_16_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_17_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_18_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_19_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_20_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_21_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_22_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_23_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_24_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_25_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_26_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_27_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_28_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_29_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_30_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_31_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_32_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_33_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_34_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_35_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_36_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_37_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_38_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_39_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_40_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_41_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_42_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_43_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_44_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_45_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_46_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_47_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_48_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_49_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_50_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_51_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_52_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_53_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_54_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_55_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_56_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_57_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_58_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_59_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_60_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_61_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_62_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_63_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_64_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_65_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_66_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_67_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_68_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_69_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_70_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_71_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_72_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_73_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_74_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_75_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_76_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_77_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_78_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_79_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_80_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_81_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_82_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_83_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_84_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_85_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_86_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_87_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_88_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_89_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_90_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_91_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_92_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_93_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_94_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_95_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_96_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_97_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_98_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_99_ solve converged due to CONVERGED_RTOL iterations 4
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

solve.py on a default named thinky with 1 processor, by connor Wed Jan  6 10:03:22 2021
Using Petsc Development GIT revision: v3.4.2-33053-ge85aaad7c1  GIT Date: 2020-10-09 10:20:17 +0100

                         Max       Max/Min     Avg       Total
Time (sec):           6.587e+00     1.000   6.587e+00
Objects:              1.631e+03     1.000   1.631e+03
Flop:                 3.207e+06     1.000   3.207e+06  3.207e+06
Flop/sec:             4.869e+05     1.000   4.869e+05  4.869e+05
MPI Messages:         0.000e+00     0.000   0.000e+00  0.000e+00
MPI Message Lengths:  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.5586e+00  54.0%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 1:  Define Problem: 2.3384e-01   3.5%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 2:   Define Solver: 7.6899e-01  11.7%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 3:           Solve: 2.0254e+00  30.7%  3.2070e+06 100.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage


--- Event Stage 1: Define Problem


--- Event Stage 2: Define Solver

BuildTwoSided          1 1.0 1.1444e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         1 1.0 1.4544e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               100 1.0 2.0957e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin     101 1.0 4.3869e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd       101 1.0 1.6015e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
CreateSparsity         1 1.0 7.0286e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroInitial       100 1.0 3.1222e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   4  0  0  0  0     0

--- Event Stage 3: Solve

VecTDot              800 1.0 2.6011e-04 1.0 4.62e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0 14  0  0  0   0 14  0  0  0  1775
VecNorm              500 1.0 5.8126e-04 1.0 2.88e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  9  0  0  0   0  9  0  0  0   496
VecCopy              600 1.0 9.4819e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet              1000 1.0 4.6706e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              900 1.0 4.4584e-04 1.0 5.20e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0 16  0  0  0   0 16  0  0  0  1167
VecAYPX              300 1.0 2.7823e-04 1.0 1.73e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  5  0  0  0   0  5  0  0  0   623
MatMult              400 1.0 1.4634e-03 1.0 1.40e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 44  0  0  0   0 44  0  0  0   954
MatConvert           100 1.0 8.6360e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin     600 1.0 1.7071e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd       600 1.0 2.8524e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetRowIJ          100 1.0 2.7418e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries       100 1.0 1.3256e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCSetUp              100 1.0 6.4875e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   3  0  0  0  0     0
PCApply              500 1.0 3.2246e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   2  0  0  0  0     0
KSPSetUp             100 1.0 2.3334e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve             100 1.0 1.1356e-01 1.0 2.78e+06 1.0 0.0e+00 0.0e+00 0.0e+00  2 87  0  0  0   6 87  0  0  0    24
SNESSolve            100 1.0 1.9162e+00 1.0 3.21e+06 1.0 0.0e+00 0.0e+00 0.0e+00 29100  0  0  0  95100  0  0  0     2
SNESSetUp            100 1.0 4.2582e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SNESFunctionEval     100 1.0 1.6406e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 25  0  0  0  0  81  0  0  0  0     0
SNESJacobianEval     100 1.0 1.5780e-01 1.0 3.68e+05 1.0 0.0e+00 0.0e+00 0.0e+00  2 11  0  0  0   8 11  0  0  0     2
ParLoopExecute       600 1.0 1.3702e-01 1.0 3.68e+05 1.0 0.0e+00 0.0e+00 0.0e+00  2 11  0  0  0   7 11  0  0  0     3
ParLoop_Cells_wrap_expression_kernel     200 1.0 5.6975e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
ApplyBC              100 1.0 7.2627e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   4  0  0  0  0     0
ParLoop_set_#x7f3998adf070_wrap_copy     200 1.0 3.2792e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
ParLoop_set_#x7f3998adf070_wrap_zero     400 1.0 9.5799e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
ParLoop_Cells_wrap_form0_cell_integral_otherwise     200 1.0 3.7124e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
ParLoop_Cells_wrap_form00_cell_integral_otherwise     200 1.0 2.4889e-02 1.0 3.68e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0 11  0  0  0   1 11  0  0  0    15
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

           Container     2              1          576     0.
              Viewer     1              0            0     0.
           Index Set    43             31        33968     0.
   IS L to G Mapping     0            200       365600     0.
             Section    17              6         4272     0.
   Star Forest Graph    16              9         8928     0.
              Vector     5            400      1552000     0.
              Matrix     2            101       293248     0.
      Preconditioner     0            100       144800     0.
       Krylov Solver     0            100       148000     0.
                SNES     0            100       140400     0.
    GraphPartitioner     2              1          660     0.
    Distributed Mesh     8              2        22792     0.
            DM Label    15              4         2528     0.
     Discrete System    10              4         3808     0.

--- Event Stage 1: Define Problem

              Vector     0             70       109760     0.
              Matrix     0             68      2152336     0.

--- Event Stage 2: Define Solver

              Viewer     1              0            0     0.
           Index Set     1              0            0     0.
   IS L to G Mapping     1              0            0     0.
   Star Forest Graph     2              1          992     0.
              Vector   200             18        28224     0.
              Matrix   101             32       984100     0.
      Preconditioner   100              0            0     0.
       Krylov Solver   100              0            0     0.
                SNES   100              0            0     0.
              DMSNES     1              0            0     0.
    Distributed Mesh     1              0            0     0.
     Discrete System     1              0            0     0.

--- Event Stage 3: Solve

   IS L to G Mapping   200              0            0     0.
              Vector   600            299       723320     0.
              Matrix   100              0            0     0.
     DMKSP interface     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 7.15256e-08
#No PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: PETSC_DIR=/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc PETSC_ARCH=default --download-ml --with-fortran-bindings=0 --download-pnetcdf --download-hypre --download-hwloc --download-chaco --with-zlib --with-shared-libraries=1 --download-pastix --download-netcdf --download-mpich --with-c2html=0 --download-superlu_dist --download-mumps --with-cxx-dialect=C++11 --download-ptscotch --download-eigen="/home/connor/projects/improve-firedrake-scaling/firedrake/src/eigen-3.3.3.tgz " --download-scalapack --download-metis --with-debugging=0 --download-hdf5 --download-suitesparse
-----------------------------------------
Libraries compiled on 2020-12-20 00:13:45 on thinky 
Machine characteristics: Linux-4.19.128-microsoft-standard-x86_64-with-glibc2.29
Using PETSc directory: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc
Using PETSc arch: default
-----------------------------------------

Using C compiler: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/bin/mpicc  -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -g -O   
Using Fortran compiler: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/bin/mpif90  -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g -O    
-----------------------------------------

Using include paths: -I/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/include -I/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/include -I/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/include/eigen3
-----------------------------------------

Using C linker: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/bin/mpicc
Using Fortran linker: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/bin/mpif90
Using libraries: -Wl,-rpath,/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/lib -L/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/lib -lpetsc -Wl,-rpath,/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/lib -L/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/9 -L/usr/lib/gcc/x86_64-linux-gnu/9 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lpastix -lumfpack -lklu -lcholmod -lbtf -lccolamd -lcolamd -lcamd -lamd -lsuitesparseconfig -lsuperlu_dist -lml -llapack -lblas -lptesmumps -lptscotchparmetis -lptscotch -lptscotcherr -lesmumps -lscotch -lscotcherr -lpthread -lhwloc -lnetcdf -lpnetcdf -lhdf5hl_fortran -lhdf5_fortran -lhdf5_hl -lhdf5 -lchaco -lmetis -lm -lz -lstdc++ -ldl -lmpifort -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lrt -lm -lrt -lstdc++ -ldl
-----------------------------------------

Discretization: CG1 on 1 MPI processes
	Degrees-of-freedom: 289
	Wall-clock time:  3.054e-02 seconds
	L2 error norm: 3.476e-02
	Digits of accuracy:  1.459e+00
	DoA/s:  4.777e+01
	DoF/s:  9.462e+03
