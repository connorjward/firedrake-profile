  Linear firedrake_0_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_1_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_2_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_3_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_4_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_5_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_6_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_7_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_8_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_9_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_10_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_11_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_12_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_13_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_14_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_15_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_16_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_17_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_18_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_19_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_20_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_21_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_22_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_23_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_24_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_25_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_26_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_27_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_28_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_29_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_30_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_31_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_32_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_33_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_34_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_35_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_36_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_37_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_38_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_39_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_40_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_41_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_42_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_43_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_44_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_45_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_46_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_47_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_48_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_49_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_50_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_51_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_52_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_53_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_54_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_55_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_56_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_57_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_58_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_59_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_60_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_61_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_62_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_63_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_64_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_65_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_66_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_67_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_68_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_69_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_70_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_71_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_72_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_73_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_74_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_75_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_76_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_77_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_78_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_79_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_80_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_81_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_82_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_83_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_84_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_85_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_86_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_87_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_88_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_89_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_90_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_91_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_92_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_93_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_94_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_95_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_96_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_97_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_98_ solve converged due to CONVERGED_RTOL iterations 4
  Linear firedrake_99_ solve converged due to CONVERGED_RTOL iterations 4
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

solve.py on a default named thinky with 1 processor, by connor Wed Jan  6 10:03:30 2021
Using Petsc Development GIT revision: v3.4.2-33053-ge85aaad7c1  GIT Date: 2020-10-09 10:20:17 +0100

                         Max       Max/Min     Avg       Total
Time (sec):           7.094e+00     1.000   7.094e+00
Objects:              1.631e+03     1.000   1.631e+03
Flop:                 3.207e+06     1.000   3.207e+06  3.207e+06
Flop/sec:             4.521e+05     1.000   4.521e+05  4.521e+05
MPI Messages:         0.000e+00     0.000   0.000e+00  0.000e+00
MPI Message Lengths:  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 5.3848e+00  75.9%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 1:  Define Problem: 2.7323e-01   3.9%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 2:   Define Solver: 9.0222e-01  12.7%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 3:           Solve: 5.3335e-01   7.5%  3.2070e+06 100.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage


--- Event Stage 1: Define Problem


--- Event Stage 2: Define Solver

BuildTwoSided          1 1.0 1.5020e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         1 1.0 2.0981e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               100 1.0 4.0793e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin     101 1.0 6.1274e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd       101 1.0 3.7725e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
CreateSparsity         1 1.0 1.0631e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroInitial       100 1.0 3.6234e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   4  0  0  0  0     0

--- Event Stage 3: Solve

VecTDot              800 1.0 2.5797e-04 1.0 4.62e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0 14  0  0  0   0 14  0  0  0  1789
VecNorm              500 1.0 4.7517e-04 1.0 2.88e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  9  0  0  0   0  9  0  0  0   607
VecCopy              600 1.0 1.3289e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet              1000 1.0 5.9342e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              900 1.0 5.2977e-04 1.0 5.20e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0 16  0  0  0   0 16  0  0  0   982
VecAYPX              300 1.0 2.6107e-04 1.0 1.73e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  5  0  0  0   0  5  0  0  0   664
MatMult              400 1.0 1.5957e-03 1.0 1.40e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 44  0  0  0   0 44  0  0  0   875
MatConvert           100 1.0 9.5980e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   2  0  0  0  0     0
MatAssemblyBegin     600 1.0 1.8549e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd       600 1.0 3.7570e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0
MatGetRowIJ          100 1.0 5.3883e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries       100 1.0 1.7047e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCSetUp              100 1.0 7.7977e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0  15  0  0  0  0     0
PCApply              500 1.0 3.6146e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   7  0  0  0  0     0
KSPSetUp             100 1.0 2.9683e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0
KSPSolve             100 1.0 1.3455e-01 1.0 2.78e+06 1.0 0.0e+00 0.0e+00 0.0e+00  2 87  0  0  0  25 87  0  0  0    21
SNESSolve            100 1.0 4.1314e-01 1.0 3.21e+06 1.0 0.0e+00 0.0e+00 0.0e+00  6100  0  0  0  77100  0  0  0     8
SNESSetUp            100 1.0 4.8089e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SNESFunctionEval     100 1.0 9.1691e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0  17  0  0  0  0     0
SNESJacobianEval     100 1.0 1.8161e-01 1.0 3.68e+05 1.0 0.0e+00 0.0e+00 0.0e+00  3 11  0  0  0  34 11  0  0  0     2
ParLoopExecute       600 1.0 1.4393e-01 1.0 3.68e+05 1.0 0.0e+00 0.0e+00 0.0e+00  2 11  0  0  0  27 11  0  0  0     3
ParLoop_Cells_wrap_expression_kernel     200 1.0 6.7446e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0
ApplyBC              100 1.0 7.9861e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0  15  0  0  0  0     0
ParLoop_set_#x7f79542fa5e0_wrap_copy     200 1.0 4.0512e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0
ParLoop_set_#x7f79542fa5e0_wrap_zero     400 1.0 6.1212e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0
ParLoop_Cells_wrap_form0_cell_integral_otherwise     200 1.0 5.1255e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0
ParLoop_Cells_wrap_form00_cell_integral_otherwise     200 1.0 2.7847e-02 1.0 3.68e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0 11  0  0  0   5 11  0  0  0    13
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

           Container     2              1          576     0.
              Viewer     1              0            0     0.
           Index Set    43             31        33968     0.
   IS L to G Mapping     0            200       365600     0.
             Section    17              6         4272     0.
   Star Forest Graph    16              9         8928     0.
              Vector     5            400      1552000     0.
              Matrix     2            101       293248     0.
      Preconditioner     0            100       144800     0.
       Krylov Solver     0            100       148000     0.
                SNES     0            100       140400     0.
    GraphPartitioner     2              1          660     0.
    Distributed Mesh     8              2        22792     0.
            DM Label    15              4         2528     0.
     Discrete System    10              4         3808     0.

--- Event Stage 1: Define Problem

              Vector     0             57        89376     0.
              Matrix     0             57      1804164     0.

--- Event Stage 2: Define Solver

              Viewer     1              0            0     0.
           Index Set     1              0            0     0.
   IS L to G Mapping     1              0            0     0.
   Star Forest Graph     2              1          992     0.
              Vector   200             37        58016     0.
              Matrix   101             43      1332272     0.
      Preconditioner   100              0            0     0.
       Krylov Solver   100              0            0     0.
                SNES   100              0            0     0.
              DMSNES     1              0            0     0.
    Distributed Mesh     1              0            0     0.
     Discrete System     1              0            0     0.

--- Event Stage 3: Solve

   IS L to G Mapping   200              0            0     0.
              Vector   600            299       723320     0.
              Matrix   100              0            0     0.
     DMKSP interface     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 4.76837e-08
#No PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: PETSC_DIR=/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc PETSC_ARCH=default --download-ml --with-fortran-bindings=0 --download-pnetcdf --download-hypre --download-hwloc --download-chaco --with-zlib --with-shared-libraries=1 --download-pastix --download-netcdf --download-mpich --with-c2html=0 --download-superlu_dist --download-mumps --with-cxx-dialect=C++11 --download-ptscotch --download-eigen="/home/connor/projects/improve-firedrake-scaling/firedrake/src/eigen-3.3.3.tgz " --download-scalapack --download-metis --with-debugging=0 --download-hdf5 --download-suitesparse
-----------------------------------------
Libraries compiled on 2020-12-20 00:13:45 on thinky 
Machine characteristics: Linux-4.19.128-microsoft-standard-x86_64-with-glibc2.29
Using PETSc directory: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc
Using PETSc arch: default
-----------------------------------------

Using C compiler: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/bin/mpicc  -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -g -O   
Using Fortran compiler: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/bin/mpif90  -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g -O    
-----------------------------------------

Using include paths: -I/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/include -I/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/include -I/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/include/eigen3
-----------------------------------------

Using C linker: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/bin/mpicc
Using Fortran linker: /home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/bin/mpif90
Using libraries: -Wl,-rpath,/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/lib -L/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/lib -lpetsc -Wl,-rpath,/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/lib -L/home/connor/projects/improve-firedrake-scaling/firedrake/src/petsc/default/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/9 -L/usr/lib/gcc/x86_64-linux-gnu/9 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lpastix -lumfpack -lklu -lcholmod -lbtf -lccolamd -lcolamd -lcamd -lamd -lsuitesparseconfig -lsuperlu_dist -lml -llapack -lblas -lptesmumps -lptscotchparmetis -lptscotch -lptscotcherr -lesmumps -lscotch -lscotcherr -lpthread -lhwloc -lnetcdf -lpnetcdf -lhdf5hl_fortran -lhdf5_fortran -lhdf5_hl -lhdf5 -lchaco -lmetis -lm -lz -lstdc++ -ldl -lmpifort -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lrt -lm -lrt -lstdc++ -ldl
-----------------------------------------

Discretization: CG1 on 1 MPI processes
	Degrees-of-freedom: 289
	Wall-clock time:  1.736e-02 seconds
	L2 error norm: 3.476e-02
	Digits of accuracy:  1.459e+00
	DoA/s:  8.402e+01
	DoF/s:  1.664e+04
